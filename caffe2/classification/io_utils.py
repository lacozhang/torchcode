import codecsinputFilePath = "/Users/edwinzhang/src/nn4nlp-code/data/classes/train.txt"inputDevPath = "/Users/edwinzhang/src/nn4nlp-code/data/classes/dev.txt"class IOUtils(object):        UNK = 0        def __init__(self, file_name):        self.fileName=file_name            def buildData(self):        self.vocab = set()        self.nclass = set()        self.data = []        with codecs.open(self.fileName, mode='r', encoding='utf-8') as textData:            for line in textData.readlines():                if len(line) < 2:                    continue                label, text = line.strip().split('|||')                label = int(label)                words = text.split(' ')                                self.data.append(                    (label, words)                )                                for word in words:                    self.vocab.add(word)                                    self.nclass.add(label)        self.UpdateMetaData()        def Vocab(self):        return self.vocab        def Labels(self):        return self.nclass        def Data(self):        return self.data        def UpdateMetaData(self):        sortedVocab = sorted(self.vocab)        self.word2idx = {            word:(idx+1) for (idx, word) in enumerate(sortedVocab)        }        self.idx2word = {            (idx+1):word for (idx, word) in enumerate(sortedVocab)        }        self.vocab.add("UNK")        self.word2idx["UNK"] = 0        self.idx2word[0] = "UNK"            def FeaturizeSentence(self, sentence):        feats = []        for word in sentence:            if word in self.word2idx:                feats.append(self.word2idx[word])            else:                feats.append(self.UNK)                return feats        def createDataset(self, inputPath):        dataset = []        with codecs.open(inputPath, mode='r', encoding='utf-8') as textData:            for line in textData.readlines():                label, text = line.strip().split('|||')                label = int(label)                words = text.split(' ')                                dataset.append(                    (label, self.FeaturizeSentence(words))                )                return dataset